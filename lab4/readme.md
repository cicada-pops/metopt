# Математическая постановка задачи оптимизации инвестиционного портфеля

## 1. Исходные данные

### 1.1. Начальное состояние портфеля
- **ЦБ1** (ценные бумаги типа 1): S₁⁰ = 100 д.е.
- **ЦБ2** (ценные бумаги типа 2): S₂⁰ = 800 д.е.
- **Деп.** (депозиты): D⁰ = 400 д.е.
- **Свободные средства**: M⁰ = 600 д.е.

### 1.2. Шаги управления
Шаг управления — изменение объёма на 1/4 от первоначальной стоимости:
- Δ₁ = 25 д.е. (для ЦБ1)
- Δ₂ = 200 д.е. (для ЦБ2)
- Δ₃ = 100 д.е. (для Деп.)

### 1.3. Коэффициенты изменения стоимости

| Этап | Ситуация | Вероятность | ЦБ1 (r₁) | ЦБ2 (r₂) | Деп. (r₃) |
|------|----------|-------------|----------|----------|-----------|
| 1 | Благоприятная | 0.60 | 1.20 | 1.10 | 1.07 |
| 1 | Нейтральная | 0.30 | 1.05 | 1.02 | 1.03 |
| 1 | Негативная | 0.10 | 0.80 | 0.95 | 1.00 |
| 2 | Благоприятная | 0.30 | 1.40 | 1.15 | 1.01 |
| 2 | Нейтральная | 0.20 | 1.05 | 1.00 | 1.00 |
| 2 | Негативная | 0.50 | 0.60 | 0.90 | 1.00 |
| 3 | Благоприятная | 0.40 | 1.15 | 1.12 | 1.05 |
| 3 | Нейтральная | 0.40 | 1.05 | 1.01 | 1.01 |
| 3 | Негативная | 0.20 | 0.70 | 0.94 | 1.00 |

---

## 2. Математическая модель

### 2.1. Переменные состояния
Вектор состояния на этапе t:
$$\mathbf{X}_t = (S_1^t, S_2^t, D^t, M^t)$$

где:
- $S_1^t$ — объём ЦБ1 на этапе t
- $S_2^t$ — объём ЦБ2 на этапе t
- $D^t$ — объём депозитов на этапе t
- $M^t$ — свободные средства на этапе t

### 2.2. Управляющие переменные
Вектор управления на этапе t:
$$\mathbf{U}_t = (u_1^t, u_2^t, u_3^t)$$

где:
- $u_1^t \in \mathbb{Z}$ — количество пакетов ЦБ1 для покупки (+) или продажи (-)
- $u_2^t \in \mathbb{Z}$ — количество пакетов ЦБ2 для покупки (+) или продажи (-)
- $u_3^t \in \mathbb{Z}$ — количество пакетов депозитов для покупки (+) или продажи (-)

### 2.3. Ограничения

**Ограничение на неотрицательность активов:**
$$S_1^t + u_1^t \cdot \Delta_1 \geq 0$$
$$S_2^t + u_2^t \cdot \Delta_2 \geq 0$$
$$D^t + u_3^t \cdot \Delta_3 \geq 0$$

**Ограничение на свободные средства (нельзя брать кредит):**
$$M^t - u_1^t \cdot \Delta_1 - u_2^t \cdot \Delta_2 - u_3^t \cdot \Delta_3 \geq 0$$

### 2.4. Уравнения перехода состояний

После применения управления и реализации ситуации j на этапе t:

$$S_1^{t+1} = (S_1^t + u_1^t \cdot \Delta_1) \cdot r_{1,t,j}$$
$$S_2^{t+1} = (S_2^t + u_2^t \cdot \Delta_2) \cdot r_{2,t,j}$$
$$D^{t+1} = (D^t + u_3^t \cdot \Delta_3) \cdot r_{3,t,j}$$
$$M^{t+1} = M^t - u_1^t \cdot \Delta_1 - u_2^t \cdot \Delta_2 - u_3^t \cdot \Delta_3$$

### 2.5. Целевая функция

Максимизировать итоговый капитал:
$$V = S_1^3 + S_2^3 + D^3 + M^3 \rightarrow \max$$

---

## 3. Рекуррентное соотношение Беллмана

### 3.1. Функция Беллмана

Обозначим $F_t(\mathbf{X}_t)$ — максимальный ожидаемый капитал, который можно получить, начиная с этапа t при состоянии $\mathbf{X}_t$.

### 3.2. Граничное условие (этап 3, терминальное состояние)
$$F_3(\mathbf{X}_3) = S_1^3 + S_2^3 + D^3 + M^3$$

### 3.3. Рекуррентное соотношение (критерий Байеса)

Для этапов t = 2, 1, 0:
$$F_t(\mathbf{X}_t) = \max_{\mathbf{U}_t \in \mathcal{U}(\mathbf{X}_t)} \left\{ \sum_{j=1}^{3} p_{t,j} \cdot F_{t+1}(\mathbf{X}_{t+1}(\mathbf{X}_t, \mathbf{U}_t, j)) \right\}$$

где:
- $p_{t,j}$ — вероятность ситуации j на этапе t
- $\mathcal{U}(\mathbf{X}_t)$ — множество допустимых управлений при состоянии $\mathbf{X}_t$
- $\mathbf{X}_{t+1}(\mathbf{X}_t, \mathbf{U}_t, j)$ — новое состояние после управления и реализации ситуации j

### 3.4. Другие критерии принятия решений

**Критерий Вальда (максимин):**
$$F_t(\mathbf{X}_t) = \max_{\mathbf{U}_t} \left\{ \min_{j} F_{t+1}(\mathbf{X}_{t+1}(\mathbf{X}_t, \mathbf{U}_t, j)) \right\}$$

**Критерий Сэвиджа (минимакс сожаления):**
$$F_t(\mathbf{X}_t) = \max_{\mathbf{U}_t} \left\{ \max_{j} F_{t+1}(\mathbf{X}_{t+1}(\mathbf{X}_t, \mathbf{U}_t, j)) - \min_{\mathbf{U}'_t} \max_{j} F_{t+1}(\mathbf{X}_{t+1}(\mathbf{X}_t, \mathbf{U}'_t, j)) \right\}$$

**Критерий Гурвица (оптимизм-пессимизм):**
$$F_t(\mathbf{X}_t) = \max_{\mathbf{U}_t} \left\{ \alpha \cdot \max_{j} F_{t+1}(\mathbf{X}_{t+1}) + (1-\alpha) \cdot \min_{j} F_{t+1}(\mathbf{X}_{t+1}) \right\}$$

где $\alpha \in [0, 1]$ — коэффициент оптимизма.

---

## 4. Алгоритм решения методом динамического программирования

### 4.1. Общая схема (обратная индукция)

```
Алгоритм: Метод динамического программирования для оптимизации портфеля

Вход:
  - Начальное состояние: X₀ = (S₁⁰, S₂⁰, D⁰, M⁰)
  - Коэффициенты изменения: r[t][j][i] для всех t, j, i
  - Вероятности: p[t][j] для всех t, j
  - Шаги управления: Δ₁, Δ₂, Δ₃
  - Выбранный критерий принятия решений

Выход:
  - Оптимальная стратегия U* = (U₀*, U₁*, U₂*)
  - Максимальный ожидаемый доход F₀(X₀)

Шаги:

1. ИНИЦИАЛИЗАЦИЯ
   1.1. Дискретизировать пространство состояний с учётом шагов Δᵢ
   1.2. Создать таблицу значений функции Беллмана F[t][X]
   1.3. Создать таблицу оптимальных управлений U*[t][X]

2. ОБРАТНЫЙ ХОД (t = 2, 1, 0)
   Для каждого этапа t от 2 до 0:
     2.1. Для каждого возможного состояния X_t:
          a) Сгенерировать множество допустимых управлений U(X_t)
          b) Для каждого управления U_t ∈ U(X_t):
             - Вычислить новые состояния X_{t+1} для всех ситуаций j
             - Вычислить значение критерия Q(U_t) по выбранному критерию:
               * Байес: Q = Σⱼ p[t][j] · F[t+1][X_{t+1}(j)]
               * Вальд: Q = minⱼ F[t+1][X_{t+1}(j)]
               * Гурвиц: Q = α·maxⱼ F[t+1][X_{t+1}(j)] + (1-α)·minⱼ F[t+1][X_{t+1}(j)]
          c) Выбрать управление U_t*, максимизирующее Q
          d) Записать F[t][X_t] = max Q и U*[t][X_t] = U_t*

3. ПРЯМОЙ ХОД (восстановление оптимальной траектории)
   3.1. X ← X₀
   3.2. Для t = 0, 1, 2:
        - Записать U*[t] = U*[t][X]
        - Обновить X по уравнениям перехода (с математическим ожиданием)

4. ВЕРНУТЬ U* и F[0][X₀]
```

### 4.2. Псевдокод генерации допустимых управлений

```
Функция: GenerateControls(S₁, S₂, D, M, Δ₁, Δ₂, Δ₃)

  controls = []
  
  # Пределы изменения для каждого актива
  u1_min = -⌊S₁/Δ₁⌋  # максимум продажи ЦБ1
  u1_max = ⌊M/Δ₁⌋    # максимум покупки ЦБ1
  
  u2_min = -⌊S₂/Δ₂⌋
  u2_max = ⌊M/Δ₂⌋
  
  u3_min = -⌊D/Δ₃⌋
  u3_max = ⌊M/Δ₃⌋
  
  Для u1 от u1_min до u1_max:
    Для u2 от u2_min до u2_max:
      Для u3 от u3_min до u3_max:
        cost = u1·Δ₁ + u2·Δ₂ + u3·Δ₃
        Если cost ≤ M:  # не превышаем свободные средства
          controls.append((u1, u2, u3))
  
  Вернуть controls
```

### 4.3. Сложность алгоритма

- **Временная сложность**: O(T · |S| · |U| · J), где:
  - T — число этапов (3)
  - |S| — размер дискретизированного пространства состояний
  - |U| — максимальное число допустимых управлений
  - J — число возможных ситуаций (3)

- **Пространственная сложность**: O(T · |S|) для хранения таблиц F и U*

---

## 5. Пример применения рекуррентного соотношения

### Этап 2 → Этап 3 (критерий Байеса)

Пусть после этапа 2 состояние: X₂ = (100, 800, 400, 600)

Рассмотрим управление U₂ = (0, 0, 0) (ничего не делать):

Для каждой ситуации j ∈ {1, 2, 3}:
- j=1 (благопр.): X₃ = (100·1.15, 800·1.12, 400·1.05, 600) = (115, 896, 420, 600)
  F₃ = 115 + 896 + 420 + 600 = 2031
- j=2 (нейтр.): X₃ = (100·1.05, 800·1.01, 400·1.01, 600) = (105, 808, 404, 600)
  F₃ = 105 + 808 + 404 + 600 = 1917
- j=3 (негат.): X₃ = (100·0.70, 800·0.94, 400·1.00, 600) = (70, 752, 400, 600)
  F₃ = 70 + 752 + 400 + 600 = 1822

Ожидаемое значение (Байес):
$$E[F_3] = 0.40 \cdot 2031 + 0.40 \cdot 1917 + 0.20 \cdot 1822 = 1943.6$$

Это значение сравнивается с другими управлениями, и выбирается максимальное.

